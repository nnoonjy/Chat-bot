import scrapy
from bs4 import BeautifulSoup
from school_crawler.items import PageItem
from datetime import datetime

class SchoolSpider(scrapy.Spider):
    name = "school"
    allowed_domains = ["cse.pusan.ac.kr"]
    start_urls = ["https://cse.pusan.ac.kr/cse/14651/subview.do"]

    def parse(self, response):
        soup = BeautifulSoup(response.text, "html.parser")

        posts = soup.select("table.artclTable tbody tr")
        if not posts:
            self.logger.warning("âš ï¸ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì…€ë ‰í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return

        for post in posts:
            title_tag = post.select_one("td._artclTdTitle a strong")
            if not title_tag:
                continue

            href = title_tag.get("href")  # ğŸ”¹ hrefê°€ ì—†ìœ¼ë©´ None ë°˜í™˜
            full_url = response.urljoin(href) if href else None

            item = PageItem()
            item["menu_cd"] = "14651"
            item["url"] = full_url
            item["title"] = title_tag.get_text(strip=True)
            item["content"] = None
            item["crawled_at"] = datetime.now()

            print("ğŸ’¾ Saving item:", item["title"])
            yield item

            # í˜ì´ì§€ë„¤ì´ì…˜ (ë‹¤ìŒ í˜ì´ì§€ ë§í¬ ë”°ë¼ê°€ê¸°)
        next_page = soup.select_one("a.pg_next")
        if next_page and next_page.get("href"):
            yield response.follow(next_page["href"], callback=self.parse)